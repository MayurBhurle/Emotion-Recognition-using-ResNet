{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4rGzMjaw0Jp"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization, Activation\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import plot_model\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "# Data Generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2,\n",
        "    rotation_range=5,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_dataset = train_datagen.flow_from_directory(\n",
        "    directory='../input/train',\n",
        "    target_size=(48, 48),\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    batch_size=64\n",
        ")\n",
        "\n",
        "valid_dataset = valid_datagen.flow_from_directory(\n",
        "    directory='../input/train',\n",
        "    target_size=(48, 48),\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    batch_size=64\n",
        ")\n",
        "\n",
        "test_dataset = test_datagen.flow_from_directory(\n",
        "    directory='../input/test',\n",
        "    target_size=(48, 48),\n",
        "    class_mode='categorical',\n",
        "    batch_size=64\n",
        ")\n",
        "\n",
        "# Base Model (ResNet50)\n",
        "base_model = ResNet50(input_shape=(48, 48, 3), include_top=False, weights=\"imagenet\")\n",
        "\n",
        "# Freeze Layers\n",
        "for layer in base_model.layers[:-4]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Model Architecture\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    Dropout(0.5),\n",
        "    Flatten(),\n",
        "    BatchNormalization(),\n",
        "    Dense(32, kernel_initializer='he_uniform'),\n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(32, kernel_initializer='he_uniform'),\n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(32, kernel_initializer='he_uniform'),\n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    Dense(7, activation='softmax')\n",
        "])\n",
        "\n",
        "# Model Summary\n",
        "model.summary()\n",
        "\n",
        "# Custom F1 Score\n",
        "def f1_score(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
        "\n",
        "# Metrics\n",
        "METRICS = [\n",
        "    tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
        "    tf.keras.metrics.Precision(name='precision'),\n",
        "    tf.keras.metrics.Recall(name='recall'),\n",
        "    tf.keras.metrics.AUC(name='auc'),\n",
        "    f1_score\n",
        "]\n",
        "\n",
        "# Callbacks\n",
        "lrd = ReduceLROnPlateau(monitor='val_loss', patience=20, verbose=1, factor=0.5, min_lr=1e-10)\n",
        "mcp = ModelCheckpoint('model.h5', save_best_only=True, verbose=1)\n",
        "es = EarlyStopping(patience=20, verbose=1, restore_best_weights=True)\n",
        "\n",
        "# Compile Model\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=METRICS)\n",
        "\n",
        "# Train Model\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=valid_dataset,\n",
        "    epochs=60,\n",
        "    callbacks=[lrd, mcp, es],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Plotting Function\n",
        "def train_val_plot(history):\n",
        "    metrics = ['accuracy', 'loss', 'auc', 'precision', 'f1_score']\n",
        "    fig, axs = plt.subplots(1, 5, figsize=(20, 5))\n",
        "    for i, metric in enumerate(metrics):\n",
        "        axs[i].plot(history.history[metric], label=f'Train {metric}')\n",
        "        axs[i].plot(history.history[f'val_{metric}'], label=f'Val {metric}')\n",
        "        axs[i].set_title(f'{metric.capitalize()} Over Epochs')\n",
        "        axs[i].legend()\n",
        "    plt.show()\n",
        "\n",
        "train_val_plot(history)\n"
      ]
    }
  ]
}